{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3538943f",
   "metadata": {},
   "source": [
    "使用Hugging Face CLI下载模型\n",
    "```\n",
    "pip install huggingface_hub\n",
    "huggingface-cli download --resume-download  \"Qwen/Qwen3-4B\" --local-dir /root/Qwen/Qwen-4B\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ba781",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "使用vllm部署Qwen3-4B模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ee875a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "source": [
    "`Qwen3-4B`是兼容`OpenAI API`协议，因此可以直接使用`vLLM`创建`OpenAI服务器`，默认会创建在 http://localhost:8000, 服务器当前一次托管一个模型，并实现列表模型、`completions`和`Chat completions`端口\n",
    "- `completions`：是基于文本生成任务,模型会在给定一段体时候生成一段文本,适用于生成文章、故事和邮件\n",
    "- `Chat completions`：面向对话任务, 模型需要理解和生成对话。用于对话机器人或对话系统\n",
    "创建服务器可以指定模型磨成、模型路径、聊天模版等参数\n",
    "- `--host`和`--port`参数指定地址\n",
    "- `--model` 参数制定模型名称\n",
    "- `--chat-template` 指定聊天模版\n",
    "- `--served-model-name` 指定服务模型的名称。\n",
    "- `--max-model-len` 指定模型的最大长度。\n",
    "- `--enable-reasoning` 开启思考模式\n",
    "- `--reasoning-parser` 指定如何解析模型生成的推理内容"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7708c8a",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "source": [
    "可以使用以下命令到终端上,启动Qwen3-4B模型的API接口\n",
    "```bash\n",
    "VLLM_USE_MODELSCOPE=true vllm serve /root/Qwen/Qwen-4B --served-model-name Qwen3-4B --max_model_len 4096 --enable-reasoning --reasoning-parser deepseek_r1 --gpu-memory-utilization 0.7\n",
    "```\n",
    "\n",
    "可以通过--gpu-memory-utilization 0.7来限制显存的利用率以便去处理其他的embedding模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3a0703",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
